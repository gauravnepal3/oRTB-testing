version: "3.9"

services:
  kafka:
    image: apache/kafka:4.1.0
    container_name: kafka
    ports: [ "9094:9094" ]   # host access for CLI/tools
    environment:
      KAFKA_NODE_ID: "1"
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_LISTENERS: "PLAINTEXT://:29092,EXTERNAL://:9094,CONTROLLER://:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:29092,EXTERNAL://localhost:9094"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_CLUSTER_ID: "q1shixmKQ9O5aH3hRkJv3g"
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
      KAFKA_NUM_PARTITIONS: "3"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: "0"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD-SHELL", "bash -lc 'bin/kafka-broker-api-versions.sh --bootstrap-server localhost:29092 >/dev/null 2>&1'"]
      interval: 10s
      timeout: 5s
      retries: 60
      start_period: 90s
    volumes: [ "kafka_data:/var/lib/kafka/data" ]
    restart: unless-stopped

  clickhouse:
    image: clickhouse/clickhouse-server:head-alpine
    container_name: clickhouse
    ports: [ "8123:8123", "9000:9000" ]
    environment:
      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: topSecretPassword
      CLICKHOUSE_DB: default
    healthcheck:
      test: ["CMD-SHELL", "clickhouse-client --user=default --password=topSecretPassword --query='SELECT 1' >/dev/null 2>&1"]
      interval: 10s
      timeout: 5s
      retries: 60
      start_period: 60s
    volumes: [ "clickhouse_data:/var/lib/clickhouse" ]
    restart: unless-stopped

  rtb-app:
    build:
      context: .
      dockerfile: Dockerfile
    image: ortb-testing-app:latest
    environment:
      # common app defaults; overridden per-env
      KAFKA_TOPIC_REQUESTS: rtb_requests
      KAFKA_TOPIC_RESPONSES: rtb_responses
      KAFKA_ACKS: "0"
      KAFKA_COMPRESSION: lz4
      KAFKA_BATCHBYTES: "262144"
      KAFKA_LINGERMS: "5"

      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: topSecretPassword

      FANOUT_COUNT: "2"
      FANOUT_MAX_INFLIGHT: "1800"
      AUCTION_IMMEDIATEACK: "true"
      SPRING_THREADS_VIRTUAL_ENABLED: "true"

      JAVA_TOOL_OPTIONS: >-
        -Djava.net.preferIPv4Stack=true
        -Dnetty.pool.maxPerHost=4000
        -Dnetty.pool.maxPending=50000
        -Dnetty.pool.acquireTimeoutMs=150
        -Dnetty.client.aggMaxBytes=262144
        -Dnetty.connect.ms=100
        -Dresp.max.bytes=65536
        -XX:+UseG1GC -XX:MaxGCPauseMillis=50
    depends_on:
      kafka:
        condition: service_started
      clickhouse:
        condition: service_healthy
    restart: unless-stopped

  prometheus:
    image: prom/prometheus
    ports: [ "9090:9090" ]
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    ports: [ "3000:3000" ]
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_USERS_ALLOW_SIGN_UP: "false"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      # (optional) mount dashboards if you add them later:
      # - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
    depends_on:
      - prometheus
    restart: unless-stopped

volumes:
  kafka_data:
  clickhouse_data:
  grafana_data: